---
title: Building Multilingual Data Science Teams
subtitle: Should we use R or Python? Yes.
author: |
  | Michael Thomas, M.S.
  | Chief Data Scientist
  | Ketchbrook Analytics
format:
  revealjs:
    theme: sky
    logo: www/ketchbrook_logo.png
    incremental: false
    transition: slide
    preview-links: true
---

## Language Wars!

![](www/r-is-dead-linkedin-post.png)

::: {.notes}

- This is a LinkedIn post that was making the rounds a few months ago; I'm sure maybe even a few of you saw it.
- It got a lot of buzz online, re-igniting the so-called "language wars" that would pop up every once in awhile in the pre-Elon Twitter days... simpler times...
- My experience with the R vs. Python debate is a little bit different and doesn't take a side

:::

## The Reality

. . .

> Amost everything that used to make Python awesome that wasn't in R has been since ported over to R.

. . .

> And everything that used to make R awesome that wasn't in Python has been since ported over to Python.

::: {.notes}

- Potentially hot take incoming?
- < read slide >

:::

## Why Have a Multilingual Team?

<br>

::: {.incremental}

- Larger potential talent pool
- More tools in the toolbox
- Dual offering

:::

::: {.notes}

- So Michael, if all of the good stuff is in both languages, then why not just pick one?  I can think of at least 3 reasons why...
- First, if you're looking for good data science candidates to build out your team, limiting your search to only candidates who know one language or the other can slow your hiring process
- Second, once in awhile, I *will* run into a problem I'm trying to solve where one language has the perfect package and the other doesn't
- Lastly, I work at a consulting firm, and the fact that we can offer our clients the option to *choose* the language they want us to build the solution in is huge

:::

## The Key to a Great Multilingual Data Science Team?

. . .

![](www/empathy2.png){height=450}

::: {.notes}

- So now that I've convinced you that a multilingual data science team can provide a lot of benefits, I'm going to give you the secret to making it work
- So this is going to sound non-technical, but I've found that the key to making multilingual data science teams work is an extra dose of empathy
- I'd argue that empathy is an important ingredient in *any* data science team, but especially so for teams using R & Python

:::

## How Empathy Manifests *Technically*

<br>

. . .

üåç Environment management
<br>

. . .

üì¶ Package choices
<br>

. . .

üìù Documentation

::: {.notes}

- I'm going to focus on *technical* things you can do that are empathetic towards others on your team < read slide >


:::

## Environment Management {transition="none"}

<br>

> *"It works on my machine"*

::: {.notes}

* "It works on my machine"
    + There are still lots of folks out there dealing with this day in & day out
    + There are also people that don't care -- because they are essentially a lone wolf
        + I still think these people should care about this... it's a short-sighted approach

:::

## Environment Management {transition="none"}

<br>

::: {.incremental}

1. Operating System
1. Python and/or R version
1. Package versions

:::

::: {.notes}

* Requires 3 things:
    + Operating System
    + Python and/or R version
    + Package versions

:::

## Environment Management {transition="none"}

<br>

::: {.columns}
::: {.column}

**Operating System & Python/R Version**

<br>

- Third-party tools:
    + Posit Workbench
- Open Source tools:
    + Containers (Docker / Podman)
    + Nix

:::
::: {.column}

**Package Version**

- Python
    + `uv`, `venv`, etc.
- R
    + {renv}

:::
:::

::: {.notes}

- On the Operating System & Python/R Version side, you can typically use the same tooling for both
- There are three best approaches to doing this < read slide >
- Going the open source approach requires some DevOps skillsets
    + Need to ask yourself if that's something you want to undertake or not
    + Cost / benefit of 3rd party tools (not saying Posit tooling doesn't have another million incredible features -- I'm just looking at this from an environment management standpoint)
- On the package versioning side, using *virtual environments* which allow you to manage package versions on a project-by-project basis, instead of having some sort of global library for all projects, can be really efficient for collaboration and ensuring you and the rest of your team are working within the same setup
    + I think there are essentially two leaders these days: `uv` on the Python side, and {renv} on the R side

:::

## Package Choices

![](www/michael-speech-bubble.png)

::: {.notes}

- We just talked about package versions, but let's talk about choosing which package to use at all -- this is pillar number 2
- Here's the question I'm always asking myself
- The choice of packages you use is the second thing that can really drive success for an effective multilingual team

:::

## Package Choices

<br>

::: {.columns}
::: {.column}

```{.r}
library(dplyr)

df <-
    mtcars |>
        filter(
            mpg > 20
        ) |>
        select(wt) |>
        arrange(desc(wt)) |>
        head(5)
#
```

![](www/dplyr-logo.png)

:::
::: {.column}

```{.python}
import polars as pl

df = (
    mtcars
    .filter(
        (pl.col("mpg") > 20)
    )
    .select("wt")
    .sort("wt", descending=True)
    .head(5)
)
```

![](www/polars-logo.png)

:::
:::

::: {.notes}

- This goes somewhat back to my slide where I mentioned that everything great in each language had been ported to the other language, but it somewhat goes beyond that; I think the great *ideas* are being borrowed from each language
- The python package {polars} is a great example. The author of polars, Ritchie Vink, has mentioned in a bunch of interviews that {polars} takes a lot inspiration from the tidyverse in R
- We know that data prep is 80% of data science, so the methodology and opinions you choose for your data prep code is important
- Our choice is typically {polars} for Python data prep or {dplyr} for R data prep
- {polars} is already pretty good at this, but in situations where we need to manipulate "big data" and {dplyr} isn't providing enough horsepower, you could opt for the {arrow} R package to continue to leverage a lot of {dplyr} syntax, but there's another interesting option that's perhaps even more language agnostic, courtesy of a Posit Conf keynote speaker last year...

:::

## Package Choices

![](www/duckdb-logo.png)

## Package Choices

<br>

::: {.columns}
::: {.column}

```{.r}
library(duckdb)

# Connect to DuckDB (in-memory db)
conn <- dbConnect(duckdb::duckdb())

# Define SQL query
query <- "
    SELECT wt
    FROM mtcars
    WHERE mpg > 20
    ORDER BY wt DESC
    LIMIT 5
"

# Execute query and get results
result <- dbGetQuery(conn, query)
```

:::
::: {.column}

```{.python}
import duckdb

# Connect to DuckDB (in-memory db)
conn = duckdb.connect()

# Define SQL query
query = """
    SELECT wt
    FROM mtcars
    WHERE mpg > 20
    ORDER BY wt DESC
    LIMIT 5
"""

# Execute query and get results
result = conn.execute(query).df()
```

:::
:::

::: {.notes}

- In each language, there's a bit of setup in the front (to connect to the database) and some small syntactic differences at the end of the script -- but everything in the middle is SQL!  The middle of your code should be almost exactly identical regardless of which language you're using -- SQL will not die
- Other similar package comparisons:
    + Use {great-tables} (Python) or {GT} (R)
    + Use {plotnine} (Python) or {ggplot2} (R)
- **Comment, comment, comment** your code (talking about inline comments; we'll talk about other types of documentation shortly)
- Lastly, if you're coming from Python and working with an R team that doesn't have a lot of OOP experience (I'd argue that R is used more as a  functional programming language than it is an OOP language), you may want to avoid OOP when a functional approach is just as good

:::

<!-- ## Documentation

* Docstrings / Roxygen should be structured similarly
* Quarto!
* GitHub Pages
* Standardized approach to READMEs
* Robust explanations within GitHub Issues and PRs (should feel like hand-holding)
    + This can be hard in a fast-paced environment with tight deadlines, but it will *save* you time in the long run (assuming you're actually taking the time to review)
* Mermaidjs

- Docstrings / Roxygen
- GitHub Workflow (SDLC)
- `README` standardization -->

## Documentation

<br>

![](www/git-sdlc.png)

::: {.notes}

- Let's move on to the last pillar of an effective multilingual data science team: Documentation
- If you're on a data science team, there are probably a few different approaches to how you could structure collaborative workflows when working on projects together.
- I'm going to show our current approach, which I believe is not only ours, but a similar workflow to what's in place at other organizations we've seen, including Posit
- First, a user or developer identifies a bug in the software or comes up with an enhancement that we've agreed to implement
- They write up their idea in a detailed "issue"
- The first step in working on that is to create a new git *branch* in the repository specifically for the purpose of addressing that "issue"
- Then they go off and write or modify the code that fixes the bug or adds the enhancement
- And once they feel like the updated code is in a good spot, they can write up a Pull Request (or "PR") that details how they addressed the issue, what changed, and more

:::

## Documentation

![](www/good-issue.mp4)

## Final Thoughts

<br>

![](www/final-thoughts.png)

::: {.notes}

- Empathy mindset; put yourself in the shoes of the reviewer or other team members that may be looking at your code
- Our team is actually multinlingual not just from a programming language perspective, but also from a spoken language perspective -- there are folks for whom English is their second language; the idiosynchracies that exist within each of our native languages can lead to someone saying something that may be interpreted as incorrect or even offensive -- make sure you figure out what their intention was with that statement before reacting
    + If you're on the other side of that, make sure you're using language that's as straightforward as possible, or preface what you want to say with something like "I don't know if I'm saying this right..."
    + Sometimes this can be just as much the case, or just as important, with 2 individuals who are both native English speakers

:::

<!-- ### Feedback

- Add some visual cues that make it obvious to separate 3rd party environment management tooling () and open source tooling
- Don't need to
- Can we pull out any stories?
- Put a Minimum Reproducible Example in your issues!!

- Add examples

- "In the pillar of Package Choices, empathy means syntax similarity for easy code review"
    + Do this for all pillars

- "In a talk where we're discussing how to try and bridge the worlds of Python and R, we can't even agree on whether we should use the term 'Multilingual' or 'Polyglot'

- Add examples of {ggplot2}/{plotnine} and {GT}/{great-tables}


-->

-